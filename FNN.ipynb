{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db561ee9-f4dc-4474-a255-4d3ad7e73b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 04:41:37.770511: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-14 04:41:37.781752: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734151297.794792   13630 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734151297.798548   13630 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-14 04:41:37.811536: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-12-14 04:41:39.274866: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4115 - loss: 1.4190 \n",
      "Epoch 2/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8046 - loss: 0.8642\n",
      "Epoch 3/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9345 - loss: 0.5240 \n",
      "Epoch 4/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9527 - loss: 0.3338 \n",
      "Epoch 5/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9652 - loss: 0.2185 \n",
      "Epoch 6/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9806 - loss: 0.1220 \n",
      "Epoch 7/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9809 - loss: 0.1122 \n",
      "Epoch 8/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9890 - loss: 0.0805 \n",
      "Epoch 9/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0740 \n",
      "Epoch 10/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0621 \n",
      "Epoch 11/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0441 \n",
      "Epoch 12/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9935 - loss: 0.0378 \n",
      "Epoch 13/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0374 \n",
      "Epoch 14/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0261 \n",
      "Epoch 15/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9965 - loss: 0.0231 \n",
      "Epoch 16/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0155 \n",
      "Epoch 17/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0120 \n",
      "Epoch 18/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0117 \n",
      "Epoch 19/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0097 \n",
      "Epoch 20/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9983 - loss: 0.0084 \n",
      "Epoch 21/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0076 \n",
      "Epoch 22/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0065 \n",
      "Epoch 23/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 24/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0041 \n",
      "Epoch 25/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0043 \n",
      "Epoch 26/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0033 \n",
      "Epoch 27/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0033 \n",
      "Epoch 28/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0028 \n",
      "Epoch 29/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0028 \n",
      "Epoch 30/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0023 \n",
      "Epoch 31/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0021 \n",
      "Epoch 32/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0021 \n",
      "Epoch 33/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0017     \n",
      "Epoch 34/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0016     \n",
      "Epoch 35/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0018 \n",
      "Epoch 36/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0014 \n",
      "Epoch 37/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013 \n",
      "Epoch 38/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0015 \n",
      "Epoch 39/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0012     \n",
      "Epoch 40/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0011     \n",
      "Epoch 41/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.4834e-04 \n",
      "Epoch 42/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0011 \n",
      "Epoch 43/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.7029e-04 \n",
      "Epoch 44/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.2331e-04 \n",
      "Epoch 45/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0010 \n",
      "Epoch 46/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.6370e-04 \n",
      "Epoch 47/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3672e-04 \n",
      "Epoch 48/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8913e-04 \n",
      "Epoch 49/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.3291e-04 \n",
      "Epoch 50/50\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5000e-04\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Step 1: Combine the individual datasets\n",
    "df_a = pd.read_csv('a.csv')\n",
    "df_b = pd.read_csv('b.csv')\n",
    "df_c = pd.read_csv('c.csv')\n",
    "df_d = pd.read_csv('d.csv')\n",
    "df_e = pd.read_csv('e.csv')\n",
    "\n",
    "# Add labels for each dataset\n",
    "df_a['letter'] = 'A'\n",
    "df_b['letter'] = 'B'\n",
    "df_c['letter'] = 'C'\n",
    "df_d['letter'] = 'D'\n",
    "df_e['letter'] = 'E'\n",
    "\n",
    "df = pd.concat([df_a, df_b, df_c, df_d, df_e])\n",
    "\n",
    "# Step 2: Feature engineering\n",
    "features = ['Flex1', 'Flex2', 'Flex3', 'Flex4', 'Flex5', 'Accel X', 'Accel Y', 'Accel Z']\n",
    "X = df[features]\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['letter'])\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Training\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(8,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "# Step 5: Evaluation\n",
    "accuracy = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "254176d2-4da3-4bf0-aa5b-8b4fd68df905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cf401a7-a2ca-4c42-acca-a1afa7fb4005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Save the model\n",
    "model.save('FNNtrained_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2570eb75-f826-4241-9d9a-1592ad360681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1219\n",
      "Test set size: 305\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "540e586e-7b8c-4720-9486-76affc3ae330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of overlapping rows between train and test: 0\n"
     ]
    }
   ],
   "source": [
    "overlap = set(map(tuple, X_train)) & set(map(tuple, X_test))\n",
    "print(\"Number of overlapping rows between train and test:\", len(overlap))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdb08d35-6354-4d21-8bf3-158579f58652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training set: 2    257\n",
      "1    253\n",
      "0    243\n",
      "4    239\n",
      "3    227\n",
      "Name: count, dtype: int64\n",
      "Class distribution in test set: 3    87\n",
      "2    61\n",
      "1    61\n",
      "0    52\n",
      "4    44\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Class distribution in training set:\", pd.Series(y_train).value_counts())\n",
    "print(\"Class distribution in test set:\", pd.Series(y_test).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdce95d9-1bc9-4a9b-92d9-9dc7d4bc3897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Predicted classes: [2 0 3 4 2 3 2 4 3 3]\n",
      "Actual classes: [2 0 3 4 2 3 2 4 3 3]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "print(\"Predicted classes:\", y_pred[:10])\n",
    "print(\"Actual classes:\", y_test[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4fda19b-2e42-4c09-9c20-7172d7ec79d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [2 0 3 4 2 3 2 4 3 3]\n",
      "Actual classes: [2 0 3 4 2 3 2 4 3 3]\n",
      "Unique predictions: [0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# Check a few predictions\n",
    "print(\"Predicted classes:\", y_pred[:10].flatten())\n",
    "print(\"Actual classes:\", y_test[:10])\n",
    "\n",
    "# Check if all predictions are identical\n",
    "unique_predictions = np.unique(y_pred)\n",
    "print(f\"Unique predictions: {unique_predictions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "972ad841-f9e4-425b-aaec-cf9ef238a901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00        52\n",
      "           B       1.00      1.00      1.00        61\n",
      "           C       1.00      1.00      1.00        61\n",
      "           D       1.00      1.00      1.00        87\n",
      "           E       1.00      1.00      1.00        44\n",
      "\n",
      "    accuracy                           1.00       305\n",
      "   macro avg       1.00      1.00      1.00       305\n",
      "weighted avg       1.00      1.00      1.00       305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "266327b9-90fa-4daf-88c5-e8a9307ea6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.7569e-04 - val_accuracy: 1.0000 - val_loss: 9.0427e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.7235e-04 - val_accuracy: 1.0000 - val_loss: 9.1575e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.0245e-04 - val_accuracy: 1.0000 - val_loss: 8.8655e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.6595e-04 - val_accuracy: 1.0000 - val_loss: 8.9089e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.2525e-04 - val_accuracy: 1.0000 - val_loss: 8.4545e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.3854e-04 - val_accuracy: 1.0000 - val_loss: 8.5668e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.6672e-04 - val_accuracy: 1.0000 - val_loss: 8.3119e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.8675e-04 - val_accuracy: 1.0000 - val_loss: 8.2067e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.4751e-04 - val_accuracy: 1.0000 - val_loss: 8.1426e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.6656e-04 - val_accuracy: 1.0000 - val_loss: 7.9795e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.6307e-04 - val_accuracy: 1.0000 - val_loss: 7.9350e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.7466e-04 - val_accuracy: 1.0000 - val_loss: 7.7868e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.7568e-04 - val_accuracy: 1.0000 - val_loss: 7.6964e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.1500e-04 - val_accuracy: 1.0000 - val_loss: 7.5073e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.2643e-04 - val_accuracy: 1.0000 - val_loss: 7.5009e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.7072e-04 - val_accuracy: 1.0000 - val_loss: 7.2388e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.2906e-04 - val_accuracy: 1.0000 - val_loss: 7.2381e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.3438e-04 - val_accuracy: 1.0000 - val_loss: 7.2834e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.9654e-04 - val_accuracy: 1.0000 - val_loss: 7.0440e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.9192e-04 - val_accuracy: 1.0000 - val_loss: 6.9663e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.4707e-04 - val_accuracy: 1.0000 - val_loss: 6.8814e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.1463e-04 - val_accuracy: 1.0000 - val_loss: 6.7217e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.3080e-04 - val_accuracy: 1.0000 - val_loss: 6.7311e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9309e-04 - val_accuracy: 1.0000 - val_loss: 6.6166e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1934e-04 - val_accuracy: 1.0000 - val_loss: 6.4686e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9600e-04 - val_accuracy: 1.0000 - val_loss: 6.4253e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1918e-04 - val_accuracy: 1.0000 - val_loss: 6.1782e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2302e-04 - val_accuracy: 1.0000 - val_loss: 6.2075e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7998e-04 - val_accuracy: 1.0000 - val_loss: 6.2204e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0062e-04 - val_accuracy: 1.0000 - val_loss: 6.0305e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1641e-04 - val_accuracy: 1.0000 - val_loss: 5.9591e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7443e-04 - val_accuracy: 1.0000 - val_loss: 5.8989e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7290e-04 - val_accuracy: 1.0000 - val_loss: 5.9795e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4755e-04 - val_accuracy: 1.0000 - val_loss: 5.8364e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1635e-04 - val_accuracy: 1.0000 - val_loss: 5.9161e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3806e-04 - val_accuracy: 1.0000 - val_loss: 5.8208e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1082e-04 - val_accuracy: 1.0000 - val_loss: 5.7007e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2152e-04 - val_accuracy: 1.0000 - val_loss: 5.4640e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4547e-04 - val_accuracy: 1.0000 - val_loss: 5.5805e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0096e-04 - val_accuracy: 1.0000 - val_loss: 5.4671e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1197e-04 - val_accuracy: 1.0000 - val_loss: 5.4619e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9728e-04 - val_accuracy: 1.0000 - val_loss: 5.3393e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9819e-04 - val_accuracy: 1.0000 - val_loss: 5.2516e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6871e-04 - val_accuracy: 1.0000 - val_loss: 5.3509e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6130e-04 - val_accuracy: 1.0000 - val_loss: 5.3697e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9928e-04 - val_accuracy: 1.0000 - val_loss: 5.0197e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6253e-04 - val_accuracy: 1.0000 - val_loss: 4.9776e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8165e-04 - val_accuracy: 1.0000 - val_loss: 4.9364e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5517e-04 - val_accuracy: 1.0000 - val_loss: 5.0429e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6335e-04 - val_accuracy: 1.0000 - val_loss: 4.9012e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d3b99ad-f397-4653-8f0d-5229c2ef2186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpa1qkm7hy/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpa1qkm7hy/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpa1qkm7hy'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 8), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140571082973856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140571082978432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140571083033584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140571083038512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140571083043792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140571083044496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1734151746.478845   13630 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1734151746.479152   13630 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2024-12-14 04:49:06.480414: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpa1qkm7hy\n",
      "2024-12-14 04:49:06.480788: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-12-14 04:49:06.480796: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpa1qkm7hy\n",
      "I0000 00:00:1734151746.483714   13630 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n",
      "2024-12-14 04:49:06.484376: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-12-14 04:49:06.507598: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpa1qkm7hy\n",
      "2024-12-14 04:49:06.513080: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 32670 microseconds.\n",
      "2024-12-14 04:49:06.543274: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the Keras model\n",
    "model = tf.keras.models.load_model('FNNtrained_model.keras')\n",
    "\n",
    "# Convert the model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6a3de18-b3ce-4333-be5c-30775c8aaa0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9kesti31/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9kesti31/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp9kesti31'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 8), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140571082973856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140571082978432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140571083033584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140571083038512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140571083043792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140571083044496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1734151805.932531   13630 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1734151805.932560   13630 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2024-12-14 04:50:05.932722: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp9kesti31\n",
      "2024-12-14 04:50:05.933133: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-12-14 04:50:05.933141: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmp9kesti31\n",
      "2024-12-14 04:50:05.936146: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-12-14 04:50:05.954717: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmp9kesti31\n",
      "2024-12-14 04:50:05.961046: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 28329 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Apply quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model_quant = converter.convert()\n",
    "\n",
    "# Save the quantized TensorFlow Lite model\n",
    "with open('model_quant.tflite', 'wb') as f:\n",
    "    f.write(tflite_model_quant)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
